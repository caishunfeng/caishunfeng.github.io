{"posts":[{"title":"内向者优势","text":"读后感 内向者擅于倾听和深度思考；外向者擅于寻求外部刺激； 外向者容易受到关注，给人比较深刻的印象；而内向者可能表现相对冷淡，给人印象比较冷漠，因此需要适度推广自己，让他人知道你的想法； 确定个人的边界，聚焦想要做的事情，学会拒绝； 按自己的节奏进行，适度休息，为自己充充电； 偶尔做一些和平时不一样的事情，换换口味，体验不同的生活； 自信是源自于我本身，而非我所做的事或者达成的成就； 给性格内向的人的一些话 享受生活，做你自己 欣赏你的内心世界，珍视你的好奇心 做一个真实可信的人 记住，让你的光芒洒向四方","link":"/2021/05/09/Introvert-Advantage/"},{"title":"DolphinScheduler-任务日志","text":"Apache DolphinScheduler 是一个分布式易扩展的可视化DAG工作流任务调度开源系统。 本文主要讲解关于DS (DolphinScheduler) 的任务日志收集的实现与优化。 实现功能DS是以DAG工作流的方式将Task组装起来，在调度过程中，DAG工作流由Master节点进行分解，将任务Task分发到Worker节点上执行，每个任务执行过程中的日志均会被收集为任务日志。通过任务日志，用户可以方便地在UI上查看最新的任务执行过程。如下图所示： 实现原理通过logback SiftingAppender，可以实现动态将task日志分开打印到不同task日志文件的功能。 logback配置12345678910111213141516171819&lt;appender name=&quot;TASKLOGFILE&quot; class=&quot;ch.qos.logback.classic.sift.SiftingAppender&quot;&gt; &lt;filter class=&quot;org.apache.dolphinscheduler.server.log.TaskLogFilter&quot;/&gt; &lt;Discriminator class=&quot;org.apache.dolphinscheduler.server.log.TaskLogDiscriminator&quot;&gt; &lt;key&gt;taskAppId&lt;/key&gt; &lt;logBase&gt;${log.base}&lt;/logBase&gt; &lt;/Discriminator&gt; &lt;sift&gt; &lt;appender name=&quot;FILE-${taskAppId}&quot; class=&quot;ch.qos.logback.core.FileAppender&quot;&gt; &lt;file&gt;${log.base}/${taskAppId}.log&lt;/file&gt; &lt;encoder&gt; &lt;pattern&gt; [%level] %date{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %logger{96}:[%line] - %messsage%n &lt;/pattern&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;/encoder&gt; &lt;append&gt;true&lt;/append&gt; &lt;/appender&gt; &lt;/sift&gt;&lt;/appender&gt; Logback SiftingAppenderLogback 将编写日志记录事件的任务委托给称为附加程序的组件，而SiftingAppender组件可以通过对子appender的管理，来达到动态MDC创建不同的appender实例，实现对日志的筛选。以上logback配置主要有TaskLogFilter和TaskLogDiscriminator两部分： TaskLogFilter进行log event的过滤，如：过滤格式不匹配或者level小于配置的log event 12345678910@Overridepublic FilterReply decide(ILoggingEvent event) { FilterReply filterReply = FilterReply.DENY; if (event.getThreadName().startsWith(TaskConstants.TASK_APPID_LOG_FORMAT) &amp;&amp; event.getLoggerName().startsWith(TaskConstants.TASK_LOG_LOGGER_NAME) &amp;&amp; event.getLevel().isGreaterOrEqual(level)) { filterReply = FilterReply.ACCEPT; } return filterReply;} TaskLogDiscriminator定义taskAppId： 12345678910111213@Overridepublic String getDiscriminatingValue(ILoggingEvent event) { String key = &quot;unknown_task&quot;; if (event.getLoggerName().startsWith(TaskConstants.TASK_LOG_LOGGER_NAME)) { String threadName = event.getThreadName(); String part1 = threadName.split(Constants.EQUAL_SIGN)[1]; String prefix = TaskConstants.TASK_LOGGER_INFO_PREFIX + &quot;-&quot;; if (part1.startsWith(prefix)) { key = part1.substring(prefix.length()).replaceFirst(&quot;-&quot;, &quot;/&quot;); } } return key;} 关于优化优化前的逻辑是每个task都会用唯一的name指定一个logger，如： 123456Logger logger = LoggerFactory.getLogger(LoggerUtils.buildTaskId(LoggerUtils.TASK_LOGGER_INFO_PREFIX, taskInstance.getFirstSubmitTime(), processInstance.getProcessDefinitionCode(), processInstance.getProcessDefinitionVersion(), taskInstance.getProcessInstanceId(), taskInstance.getId())); 导致在getLogger的时候每次都会新建一个logger，而新建的过程是同步的，在高并发的情况下对性能影响严重 123456789101112131415161718192021222324@Overridepublic final Logger getLogger(final String name) { // 如果logger存在，直接返回 Logger childLogger = (Logger) loggerCache.get(name); if (childLogger != null) { return childLogger; } String childName; while (true) { // 省略部分代码 synchronized (logger) { childLogger = logger.getChildByName(childName); if (childLogger == null) { childLogger = logger.createChildByName(childName); loggerCache.put(childName, childLogger); } } logger = childLogger; if (h == -1) { return childLogger; } }} 优化思路： 用类名来指定logger，防止大量logger的创建； 收敛task操作入口，通过线程名来注入task的唯一标识，调整log的过滤逻辑和获取key的逻辑； worker的task入口收敛：TaskExecuteThread.run 1234567891011121314151617181920212223@Overridepublic void run() { // 省略部分代码 String taskLogName = LoggerUtils.buildTaskId(taskExecutionContext.getFirstSubmitTime(), taskExecutionContext.getProcessDefineCode(), taskExecutionContext.getProcessDefineVersion(), taskExecutionContext.getProcessInstanceId(), taskExecutionContext.getTaskInstanceId()); taskRequest.setTaskLogName(taskLogName); // set the name of the current thread Thread.currentThread().setName(taskLogName); task = taskChannel.createTask(taskRequest); // task init this.task.init(); // task handle this.task.handle(); // 省略部分代码} master的task入口收敛：BaseTaskProcessor.action 1234567891011121314151617181920212223242526@Overridepublic boolean action(TaskAction taskAction) { String threadName = Thread.currentThread().getName(); if (StringUtils.isNotEmpty(threadLoggerInfoName)) { Thread.currentThread().setName(threadLoggerInfoName); } switch (taskAction) { case STOP: return stop(); case PAUSE: return pause(); case TIMEOUT: return timeout(); case SUBMIT: return submit(); case RUN: return run(); case DISPATCH: return dispatch(); default: logger.error(&quot;unknown task action: {}&quot;, taskAction); } // reset thread name Thread.currentThread().setName(threadName); return false;} 参考Logback Append","link":"/2022/02/26/DolphinScheduler-Task-Log/"},{"title":"Linux性能之CPU","text":"进程vs线程 进程是系统资源分配的基本单元 线程是任务调度执行的基本单元 上下文切换 进程间上下文切换：时间片(非自愿)、资源等待(自愿)、主动sleep；IO密集型的多为自愿上下文切换，CPU密集型的多为非自愿上下文切换； 进程内上下文切换：系统调用；（用户态 -&gt; 内核态 -&gt; 用户态） 中断上下文切换：硬中断（硬件设备触发），软中断（内核触发） 相关指标 CPU使用率(用户CPU、系统CPU) 平均负载 上下文切换次数(context switch) 中断次数(自愿中断、非自愿中断) 相关工具指南（摘自linux性能优化专栏-倪朋飞） 拓展： perl-tools","link":"/2021/07/13/Linux-CPU/"},{"title":"锁","text":"意义：锁的产生是由于资源的竞争： 公平角度，可以分为公平锁、非公平锁； 意识形态，可以分为乐观锁（CAS）、悲观锁； 协同合作，如 golang 的 select/channel 机制； 锁粒度 读写分离，可以分为共享锁（读读）、排他锁（读写、写写） 数据粒度，如 MySQL 的表锁、行锁、间隙锁等；隔离级别越严格，锁颗粒越大； 线程锁优化（java）: 可重入锁（递归锁） 自旋锁（自适应自旋锁） 分布式锁： redis：redission 的实现（watchdog 机制），redlock（脑裂）； zookeeper：创建临时有序节点，并监听前一个节点变化，当自己是最小序号时可获得锁；","link":"/2021/03/21/Lock/"},{"title":"管理认知和角色定位","text":"什么是管理？ 管理的本质是：借助他们，达成目标； 资源意识：管理需要有资源意识，人、时间、预算、环境等都是资源，所以平时需要多积累资源； 眼光长远，长期主义：重结果，也重过程； 管理者有哪些角色？ 规划者：管理者需要对本部门的目标计划、组织结构、资源分配，做好短期/长期规划，分解到每一个人； 执行者：准确传递上级理念、规划、任务，明确员工职责，认知履行； 检查者：员工不会做你希望他做的，只会做你检查的；你不检查就是不重视； 教练员：团队素质低不是你的责任，不能提高他的素质就是你的责任；要求管理者不断自我提升； 内部客户：你做得好不好、行不行，不是你自己说了算，是你的内部客户说了算； 绩效伙伴：绩效共同体，相互依存，双方平等； 管理者的角色错位 ？ 土皇帝：以自我为中心，“我觉得应该”； 民意代表：管理角色是公司赋予的，既要取得下属拥戴和支持，也要对上负责； 自然人：把自己当成了普通员工，对上没有做好部门代表，对下没有做好领导决策； 传声筒：可有可无，没有作用； 目标管理 什么是目标？目标是具体明确的、可执行、可衡量、有时间限制的，符合 SMART 原则； 你/团队的目标是什么？为什么？为什么？为什么？想好为什么很重要； 目标如何拆解？选择目标路径 -&gt; 制定初步计划 -&gt; 资源获取 -&gt; 制定行动计划 -&gt; 行动实施，拆解后的目标一定要是明确可执行的目标单元；","link":"/2021/04/18/Management/"},{"title":"分布式链路追踪","text":"背景：分布式系统往往会进行模块的拆分，如：基础模块、网关模块、订单模块、库存模块等，那么当一个请求耗时过长时，我们怎么去更直观地定位问题所在呢？请求在每个模块的执行过程是怎样的？模块与模块之间是怎样的调用顺序？请求究竟卡在哪一步？从而引发一个思考：如何能清晰的描述一个请求的生命周期，帮助我们快速地定位问题。 基本思路：给每个请求生成一个唯一标识的traceId，在日志打印的加上这个traceId，模块/服务间调用时将traceId往下传，直至整个请求处理完成返回； 做法：（java实现） 模块内部对controller做AOP切面拦截，生成traceId存入线程上下文，修改日志包在日志输出时打印threadLocal的traceId 1234567891011121314151617181920212223242526272829@Aspect@Componentpublic class ControllerAspect { @Pointcut(&quot;execution(* com.xxx.xxx.controller..*(..))&quot;) public void controllerLog() { } @Around(&quot;controllerLog()&quot;) public Object doAround(ProceedingJoinPoint proceedingJoinPoint) throws Throwable { HttpServletRequest request = ((ServletRequestAttributes) RequestContextHolder.getRequestAttributes()).getRequest(); // 生成唯一的请求traceId,并加入日志链和上下文 BizContextUtil.setReqStartTime(System.currentTimeMillis()); String traceId = TraceUtil.buildTraceId(); MDC.put(BizContextUtil.TRACE_ID, traceId); BizContextUtil.setTraceId(traceId); Object result = null; try { result = proceedingJoinPoint.proceed(); LoggerUtil.SYS_LOG.info(&quot;uri:{},args:{},userId:{},ms:{}&quot;, request.getRequestURI(), JsonUtil.to(proceedingJoinPoint.getArgs()), BizContextUtil.getPortalUserId(), BizContextUtil.getUseTime()); } catch (Exception e) { LoggerUtil.SYS_LOG.error(&quot;ControllerLogAspect error,uri:{},args:{},userId:{}&quot;, request.getRequestURI(), JsonUtil.to(proceedingJoinPoint.getArgs()), BizContextUtil.getPortalUserId()); throw e; } return result; }} 日志配置traceId打印 1234567891011&lt;appender name=&quot;SYS_LOG&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt; &lt;File&gt;logs/sys.log&lt;/File&gt; &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt; &lt;fileNamePattern&gt;logs/sys-%d{yyyy-MM-dd}.log&lt;/fileNamePattern&gt; &lt;maxHistory&gt;30&lt;/maxHistory&gt; &lt;/rollingPolicy&gt; &lt;encoder&gt; &lt;pattern&gt; %d %p (%file:%line\\)- [%X{traceId}] %m%n&lt;/pattern&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;/encoder&gt;&lt;/appender&gt; 跨线程调用传递：在跨线程调用时取出前一个线程的traceId，传递给下一个线程 12345678910111213141516public static &lt;U&gt; CompletableFuture&lt;U&gt; supplyAsync(Supplier&lt;U&gt; supplier, Executor executor) { BizContext bizContext = BizContextUtil.getBizContext(); if (bizContext == null) { return CompletableFuture.supplyAsync(supplier::get, executor); } return CompletableFuture.supplyAsync( SupplierWrapper.of(() -&gt; { BizContextUtil.setBizContext(bizContext); if (StringUtil.isNotEmpty(BizContextUtil.getTraceId())) { MDC.put(BizContextUtil.TRACE_ID, BizContextUtil.getTraceId()); } U u = supplier.get(); return u; }), executor);} 跨服务调用传递：调用者往http的header设置traceId，服务提供者取出traceId放入threadLocal，如注入feign的RequestInterceptor； 12345678910111213141516@Componentpublic class FeignRequestInterceptor implements RequestInterceptor { @Override public void apply(RequestTemplate template) { if (StringUtil.isNotEmpty(BizContextUtil.getTraceId())) { template.header(BizContextUtil.TRACE_ID, BizContextUtil.getTraceId()); } if (BizContextUtil.getPortalUserId() &gt; 0) { template.header(BizContextUtil.PORTAL_USER_ID, &quot;&quot; + BizContextUtil.getPortalUserId()); } if (BizContextUtil.getUserId() &gt; 0) { template.header(BizContextUtil.USER_ID, &quot;&quot; + BizContextUtil.getUserId()); } }} 一些微服务框架如阿里的dubbo，可以利用dubbo的RpcContext分別实现DubboConsumerFilter和DubboProviderFilter，前者负责将traceId放入RPC上下文，后者则取出traceId放入threadLocal； 拓展： nodejs版实现（待补充） go版实现（待补充） SkyWalking","link":"/2021/03/14/Monitor-Trace/"},{"title":"事务隔离级别","text":"事务特性：事务有 ACID 四大特性： Atomicity（原子性）：事务中的全部操作不可分割，要么全部成功，要么全部失败； Consistency（一致性）：事务必须使数据库从一个一致性状态变换到另一个一致性状态； Isolation（隔离性）：事务在操作的过程中不会被其他事务所干扰，并发事务之间相互隔离； Durability（持久性）：事务一旦被提交了，那么对数据库中的数据的改变就是永久性的； innodb 的事务隔离级别： 隔离级别 脏读 不可重复读 幻读 Read uncommitted (读未提交) 会 会 会 Read committed (读已提交) 不会 会 会 Repeatable read (可重复读) 不会 不会 不会 Serializable (串行化) 不会 不会 不会 123456789101112131415161718192021-- 查看当前会话隔离级别select @@tx_isolation;-- 查看系统当前隔离级别select @@global.tx_isolation;-- 查看是否自动提交select @@autocommit;-- 设置当前会话的隔离级别set session transaction isolation level read committed;-- 设置全局的隔离级别set global transaction isolation level read committed;CREATE TABLE `user` (`id` int(11) unsigned NOT NULL AUTO_INCREMENT,`name` varchar(64) DEFAULT NULL,`age` int(4) DEFAULT NULL,`sex` tinyint(1) DEFAULT NULL,PRIMARY KEY (`id`),UNIQUE KEY `uniq_name` (`name`)) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8mb4; 脏读：在一个事务的处理过程中读取到了其他事务未提交的数据； Time A B 0 insert into user(name,age,sex) values(‘张三’,20,1); 1 start transaction; 2 update user set age = age + 1 where name = ‘张三’; 3 start transaction; 4 select age from user where name = ‘张三’; (result: 21) 5 rollback; Time4：虽然 A 未提交，但此时 A 事务操作的数据对 B 已可见，即产生了脏读 不可重复读：在一个事务的处理过程中查询同一记录两次的结果可能不一致（该记录被其他事务操作并提交了）； Time A B 0 insert into user(name,age,sex) values(‘张三’,20,1); 1 start transaction; 2 update user set age = age + 1 where name = ‘张三’; 3 start transaction; 4 select age from user where name = ‘张三’;(result: 20) 5 commit; 6 select age from user where name = ‘张三’;(result: 21) Time6：A 在事务 B 开启后提交，此时 B 已经可以读取到 A 事务操作的最新数据，即对 B 来说，两次读取同一记录结果不一致) 幻读：在一个事务的处理过程中相同查询执行两次，可能产生不一样的结果集，即产生幻行； Time A B 0 insert into user(name,age,sex) values(‘张三’,20,1); 1 start transaction; 2 insert into user(name,age,sex) values(‘李四’,30,1); 3 start transaction; 4 select count(1) from user; (result: 1) 5 commit; 6 select count(1) from user; (result: 2) Time6：A 在事务 B 开启后提交，此时 B 已经读取到 A 事务新增的李四这条数据，即对事务 B 来说，两次查询的结果集不一致，产生了幻行；innodb 通过 MVCC(多版本并发控制)解决幻读现象； 拓展： MVCC phantom rows","link":"/2021/03/28/Transaction-Isolation-Level/"}],"tags":[{"name":"book","slug":"book","link":"/tags/book/"},{"name":"IT","slug":"IT","link":"/tags/IT/"},{"name":"DolphinScheduler","slug":"DolphinScheduler","link":"/tags/DolphinScheduler/"},{"name":"linux","slug":"linux","link":"/tags/linux/"},{"name":"lock","slug":"lock","link":"/tags/lock/"},{"name":"management","slug":"management","link":"/tags/management/"},{"name":"trace","slug":"trace","link":"/tags/trace/"},{"name":"Database","slug":"Database","link":"/tags/Database/"}],"categories":[{"name":"DolphinScheduler","slug":"DolphinScheduler","link":"/categories/DolphinScheduler/"},{"name":"读书","slug":"读书","link":"/categories/%E8%AF%BB%E4%B9%A6/"},{"name":"Linux","slug":"Linux","link":"/categories/Linux/"},{"name":"Java","slug":"Java","link":"/categories/Java/"},{"name":"Monitor","slug":"Monitor","link":"/categories/Monitor/"},{"name":"Database","slug":"Database","link":"/categories/Database/"}],"pages":[]}