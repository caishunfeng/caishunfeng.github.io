{"posts":[{"title":"DolphinScheduler-任务日志","text":"Apache DolphinScheduler 是一个分布式易扩展的可视化DAG工作流任务调度开源系统。 本文主要讲解关于DS (DolphinScheduler) 的任务日志收集的实现与优化。 实现功能DS是以DAG工作流的方式将Task组装起来，在调度过程中，DAG工作流由Master节点进行分解，将任务Task分发到Worker节点上执行，每个任务执行过程中的日志均会被收集为任务日志。通过任务日志，用户可以方便地在UI上查看最新的任务执行过程。如下图所示： 实现原理通过logback SiftingAppender，可以实现动态将task日志分开打印到不同task日志文件的功能。 logback配置12345678910111213141516171819&lt;appender name=&quot;TASKLOGFILE&quot; class=&quot;ch.qos.logback.classic.sift.SiftingAppender&quot;&gt; &lt;filter class=&quot;org.apache.dolphinscheduler.server.log.TaskLogFilter&quot;/&gt; &lt;Discriminator class=&quot;org.apache.dolphinscheduler.server.log.TaskLogDiscriminator&quot;&gt; &lt;key&gt;taskAppId&lt;/key&gt; &lt;logBase&gt;${log.base}&lt;/logBase&gt; &lt;/Discriminator&gt; &lt;sift&gt; &lt;appender name=&quot;FILE-${taskAppId}&quot; class=&quot;ch.qos.logback.core.FileAppender&quot;&gt; &lt;file&gt;${log.base}/${taskAppId}.log&lt;/file&gt; &lt;encoder&gt; &lt;pattern&gt; [%level] %date{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %logger{96}:[%line] - %messsage%n &lt;/pattern&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;/encoder&gt; &lt;append&gt;true&lt;/append&gt; &lt;/appender&gt; &lt;/sift&gt;&lt;/appender&gt; Logback SiftingAppenderLogback 将编写日志记录事件的任务委托给称为附加程序的组件，而SiftingAppender组件可以通过对子appender的管理，来达到动态MDC创建不同的appender实例，实现对日志的筛选。以上logback配置主要有TaskLogFilter和TaskLogDiscriminator两部分： TaskLogFilter进行log event的过滤，如：过滤格式不匹配或者level小于配置的log event 12345678910@Overridepublic FilterReply decide(ILoggingEvent event) { FilterReply filterReply = FilterReply.DENY; if (event.getThreadName().startsWith(TaskConstants.TASK_APPID_LOG_FORMAT) &amp;&amp; event.getLoggerName().startsWith(TaskConstants.TASK_LOG_LOGGER_NAME) &amp;&amp; event.getLevel().isGreaterOrEqual(level)) { filterReply = FilterReply.ACCEPT; } return filterReply;} TaskLogDiscriminator定义taskAppId： 12345678910111213@Overridepublic String getDiscriminatingValue(ILoggingEvent event) { String key = &quot;unknown_task&quot;; if (event.getLoggerName().startsWith(TaskConstants.TASK_LOG_LOGGER_NAME)) { String threadName = event.getThreadName(); String part1 = threadName.split(Constants.EQUAL_SIGN)[1]; String prefix = TaskConstants.TASK_LOGGER_INFO_PREFIX + &quot;-&quot;; if (part1.startsWith(prefix)) { key = part1.substring(prefix.length()).replaceFirst(&quot;-&quot;, &quot;/&quot;); } } return key;} 关于优化优化前的逻辑是每个task都会用唯一的name指定一个logger，如： 123456Logger logger = LoggerFactory.getLogger(LoggerUtils.buildTaskId(LoggerUtils.TASK_LOGGER_INFO_PREFIX, taskInstance.getFirstSubmitTime(), processInstance.getProcessDefinitionCode(), processInstance.getProcessDefinitionVersion(), taskInstance.getProcessInstanceId(), taskInstance.getId())); 导致在getLogger的时候每次都会新建一个logger，而新建的过程是同步的，在高并发的情况下对性能影响严重 123456789101112131415161718192021222324@Overridepublic final Logger getLogger(final String name) { // 如果logger存在，直接返回 Logger childLogger = (Logger) loggerCache.get(name); if (childLogger != null) { return childLogger; } String childName; while (true) { // 省略部分代码 synchronized (logger) { childLogger = logger.getChildByName(childName); if (childLogger == null) { childLogger = logger.createChildByName(childName); loggerCache.put(childName, childLogger); } } logger = childLogger; if (h == -1) { return childLogger; } }} 优化思路： 用类名来指定logger，防止大量logger的创建； 收敛task操作入口，通过线程名来注入task的唯一标识，调整log的过滤逻辑和获取key的逻辑； worker的task入口收敛：TaskExecuteThread.run 1234567891011121314151617181920212223@Overridepublic void run() { // 省略部分代码 String taskLogName = LoggerUtils.buildTaskId(taskExecutionContext.getFirstSubmitTime(), taskExecutionContext.getProcessDefineCode(), taskExecutionContext.getProcessDefineVersion(), taskExecutionContext.getProcessInstanceId(), taskExecutionContext.getTaskInstanceId()); taskRequest.setTaskLogName(taskLogName); // set the name of the current thread Thread.currentThread().setName(taskLogName); task = taskChannel.createTask(taskRequest); // task init this.task.init(); // task handle this.task.handle(); // 省略部分代码} master的task入口收敛：BaseTaskProcessor.action 1234567891011121314151617181920212223242526@Overridepublic boolean action(TaskAction taskAction) { String threadName = Thread.currentThread().getName(); if (StringUtils.isNotEmpty(threadLoggerInfoName)) { Thread.currentThread().setName(threadLoggerInfoName); } switch (taskAction) { case STOP: return stop(); case PAUSE: return pause(); case TIMEOUT: return timeout(); case SUBMIT: return submit(); case RUN: return run(); case DISPATCH: return dispatch(); default: logger.error(&quot;unknown task action: {}&quot;, taskAction); } // reset thread name Thread.currentThread().setName(threadName); return false;} 参考Logback Append","link":"/2022/02/26/DolphinScheduler-Task-Log/"},{"title":"DolphinScheduler- 工作流实例的生命周期","text":"Apache DolphinScheduler 是一个分布式易扩展的可视化DAG工作流任务调度开源系统。 本文主要讲解关于DS (DolphinScheduler) 工作流实例的生命周期。 如何触发一个工作流实例?Command是统一入口，Master异步处理，将Command转换为工作流实例。 Workflow-DAG解析DAG构建 -&gt; 初始化数据加载 -&gt; 提交任务节点 Dispatch-分发 WorkerGroup：要分发的目标分组 轮询策略+心跳机制：如何去最优地分发任务？ 逻辑任务组件在Master执行，非逻辑任务组件在Worker执行，更具拓展性。 Master和Worker的交互过程 运行态操作暂停 | 停止 | 超时 | 重试 | 容错","link":"/2023/05/29/DolphinScheduler-The-lifecycle-of-workflow-instance/"},{"title":"内向者优势","text":"读后感 内向者擅于倾听和深度思考；外向者擅于寻求外部刺激； 外向者容易受到关注，给人比较深刻的印象；而内向者可能表现相对冷淡，给人印象比较冷漠，因此需要适度推广自己，让他人知道你的想法； 确定个人的边界，聚焦想要做的事情，学会拒绝； 按自己的节奏进行，适度休息，为自己充充电； 偶尔做一些和平时不一样的事情，换换口味，体验不同的生活； 自信是源自于我本身，而非我所做的事或者达成的成就； 给性格内向的人的一些话 享受生活，做你自己 欣赏你的内心世界，珍视你的好奇心 做一个真实可信的人 记住，让你的光芒洒向四方","link":"/2021/05/09/Introvert-Advantage/"},{"title":"Linux性能之CPU","text":"进程vs线程 进程是系统资源分配的基本单元 线程是任务调度执行的基本单元 上下文切换 进程间上下文切换：时间片(非自愿)、资源等待(自愿)、主动sleep；IO密集型的多为自愿上下文切换，CPU密集型的多为非自愿上下文切换； 进程内上下文切换：系统调用；（用户态 -&gt; 内核态 -&gt; 用户态） 中断上下文切换：硬中断（硬件设备触发），软中断（内核触发） 相关指标 CPU使用率(用户CPU、系统CPU) 平均负载 上下文切换次数(context switch) 中断次数(自愿中断、非自愿中断) 相关工具指南（摘自linux性能优化专栏-倪朋飞） 拓展： perl-tools","link":"/2021/07/13/Linux-CPU/"},{"title":"锁","text":"意义：锁的产生是由于资源的竞争： 公平角度，可以分为公平锁、非公平锁； 意识形态，可以分为乐观锁（CAS）、悲观锁； 协同合作，如 golang 的 select/channel 机制； 锁粒度 读写分离，可以分为共享锁（读读）、排他锁（读写、写写） 数据粒度，如 MySQL 的表锁、行锁、间隙锁等；隔离级别越严格，锁颗粒越大； 线程锁优化（java）: 可重入锁（递归锁） 自旋锁（自适应自旋锁） 分布式锁： redis：redission 的实现（watchdog 机制），redlock（脑裂）； zookeeper：创建临时有序节点，并监听前一个节点变化，当自己是最小序号时可获得锁；","link":"/2021/03/21/Lock/"},{"title":"管理认知和角色定位","text":"什么是管理？ 管理的本质是：借助他们，达成目标； 资源意识：管理需要有资源意识，人、时间、预算、环境等都是资源，所以平时需要多积累资源； 眼光长远，长期主义：重结果，也重过程； 管理者有哪些角色？ 规划者：管理者需要对本部门的目标计划、组织结构、资源分配，做好短期/长期规划，分解到每一个人； 执行者：准确传递上级理念、规划、任务，明确员工职责，认知履行； 检查者：员工不会做你希望他做的，只会做你检查的；你不检查就是不重视； 教练员：团队素质低不是你的责任，不能提高他的素质就是你的责任；要求管理者不断自我提升； 内部客户：你做得好不好、行不行，不是你自己说了算，是你的内部客户说了算； 绩效伙伴：绩效共同体，相互依存，双方平等； 管理者的角色错位 ？ 土皇帝：以自我为中心，“我觉得应该”； 民意代表：管理角色是公司赋予的，既要取得下属拥戴和支持，也要对上负责； 自然人：把自己当成了普通员工，对上没有做好部门代表，对下没有做好领导决策； 传声筒：可有可无，没有作用； 目标管理 什么是目标？目标是具体明确的、可执行、可衡量、有时间限制的，符合 SMART 原则； 你/团队的目标是什么？为什么？为什么？为什么？想好为什么很重要； 目标如何拆解？选择目标路径 -&gt; 制定初步计划 -&gt; 资源获取 -&gt; 制定行动计划 -&gt; 行动实施，拆解后的目标一定要是明确可执行的目标单元；","link":"/2021/04/18/Management/"},{"title":"分布式链路追踪","text":"背景：分布式系统往往会进行模块的拆分，如：基础模块、网关模块、订单模块、库存模块等，那么当一个请求耗时过长时，我们怎么去更直观地定位问题所在呢？请求在每个模块的执行过程是怎样的？模块与模块之间是怎样的调用顺序？请求究竟卡在哪一步？从而引发一个思考：如何能清晰的描述一个请求的生命周期，帮助我们快速地定位问题。 基本思路：给每个请求生成一个唯一标识的traceId，在日志打印的加上这个traceId，模块/服务间调用时将traceId往下传，直至整个请求处理完成返回； 做法：（java实现） 模块内部对controller做AOP切面拦截，生成traceId存入线程上下文，修改日志包在日志输出时打印threadLocal的traceId 1234567891011121314151617181920212223242526272829@Aspect@Componentpublic class ControllerAspect { @Pointcut(&quot;execution(* com.xxx.xxx.controller..*(..))&quot;) public void controllerLog() { } @Around(&quot;controllerLog()&quot;) public Object doAround(ProceedingJoinPoint proceedingJoinPoint) throws Throwable { HttpServletRequest request = ((ServletRequestAttributes) RequestContextHolder.getRequestAttributes()).getRequest(); // 生成唯一的请求traceId,并加入日志链和上下文 BizContextUtil.setReqStartTime(System.currentTimeMillis()); String traceId = TraceUtil.buildTraceId(); MDC.put(BizContextUtil.TRACE_ID, traceId); BizContextUtil.setTraceId(traceId); Object result = null; try { result = proceedingJoinPoint.proceed(); LoggerUtil.SYS_LOG.info(&quot;uri:{},args:{},userId:{},ms:{}&quot;, request.getRequestURI(), JsonUtil.to(proceedingJoinPoint.getArgs()), BizContextUtil.getPortalUserId(), BizContextUtil.getUseTime()); } catch (Exception e) { LoggerUtil.SYS_LOG.error(&quot;ControllerLogAspect error,uri:{},args:{},userId:{}&quot;, request.getRequestURI(), JsonUtil.to(proceedingJoinPoint.getArgs()), BizContextUtil.getPortalUserId()); throw e; } return result; }} 日志配置traceId打印 1234567891011&lt;appender name=&quot;SYS_LOG&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt; &lt;File&gt;logs/sys.log&lt;/File&gt; &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt; &lt;fileNamePattern&gt;logs/sys-%d{yyyy-MM-dd}.log&lt;/fileNamePattern&gt; &lt;maxHistory&gt;30&lt;/maxHistory&gt; &lt;/rollingPolicy&gt; &lt;encoder&gt; &lt;pattern&gt; %d %p (%file:%line\\)- [%X{traceId}] %m%n&lt;/pattern&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;/encoder&gt;&lt;/appender&gt; 跨线程调用传递：在跨线程调用时取出前一个线程的traceId，传递给下一个线程 12345678910111213141516public static &lt;U&gt; CompletableFuture&lt;U&gt; supplyAsync(Supplier&lt;U&gt; supplier, Executor executor) { BizContext bizContext = BizContextUtil.getBizContext(); if (bizContext == null) { return CompletableFuture.supplyAsync(supplier::get, executor); } return CompletableFuture.supplyAsync( SupplierWrapper.of(() -&gt; { BizContextUtil.setBizContext(bizContext); if (StringUtil.isNotEmpty(BizContextUtil.getTraceId())) { MDC.put(BizContextUtil.TRACE_ID, BizContextUtil.getTraceId()); } U u = supplier.get(); return u; }), executor);} 跨服务调用传递：调用者往http的header设置traceId，服务提供者取出traceId放入threadLocal，如注入feign的RequestInterceptor； 12345678910111213141516@Componentpublic class FeignRequestInterceptor implements RequestInterceptor { @Override public void apply(RequestTemplate template) { if (StringUtil.isNotEmpty(BizContextUtil.getTraceId())) { template.header(BizContextUtil.TRACE_ID, BizContextUtil.getTraceId()); } if (BizContextUtil.getPortalUserId() &gt; 0) { template.header(BizContextUtil.PORTAL_USER_ID, &quot;&quot; + BizContextUtil.getPortalUserId()); } if (BizContextUtil.getUserId() &gt; 0) { template.header(BizContextUtil.USER_ID, &quot;&quot; + BizContextUtil.getUserId()); } }} 一些微服务框架如阿里的dubbo，可以利用dubbo的RpcContext分別实现DubboConsumerFilter和DubboProviderFilter，前者负责将traceId放入RPC上下文，后者则取出traceId放入threadLocal； 拓展： nodejs版实现（待补充） go版实现（待补充） SkyWalking","link":"/2021/03/14/Monitor-Trace/"},{"title":"事务隔离级别","text":"事务特性：事务有 ACID 四大特性： Atomicity（原子性）：事务中的全部操作不可分割，要么全部成功，要么全部失败； Consistency（一致性）：事务必须使数据库从一个一致性状态变换到另一个一致性状态； Isolation（隔离性）：事务在操作的过程中不会被其他事务所干扰，并发事务之间相互隔离； Durability（持久性）：事务一旦被提交了，那么对数据库中的数据的改变就是永久性的； innodb 的事务隔离级别： 隔离级别 脏读 不可重复读 幻读 Read uncommitted (读未提交) 会 会 会 Read committed (读已提交) 不会 会 会 Repeatable read (可重复读) 不会 不会 不会 Serializable (串行化) 不会 不会 不会 123456789101112131415161718192021-- 查看当前会话隔离级别select @@tx_isolation;-- 查看系统当前隔离级别select @@global.tx_isolation;-- 查看是否自动提交select @@autocommit;-- 设置当前会话的隔离级别set session transaction isolation level read committed;-- 设置全局的隔离级别set global transaction isolation level read committed;CREATE TABLE `user` (`id` int(11) unsigned NOT NULL AUTO_INCREMENT,`name` varchar(64) DEFAULT NULL,`age` int(4) DEFAULT NULL,`sex` tinyint(1) DEFAULT NULL,PRIMARY KEY (`id`),UNIQUE KEY `uniq_name` (`name`)) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8mb4; 脏读：在一个事务的处理过程中读取到了其他事务未提交的数据； Time A B 0 insert into user(name,age,sex) values(‘张三’,20,1); 1 start transaction; 2 update user set age = age + 1 where name = ‘张三’; 3 start transaction; 4 select age from user where name = ‘张三’; (result: 21) 5 rollback; Time4：虽然 A 未提交，但此时 A 事务操作的数据对 B 已可见，即产生了脏读 不可重复读：在一个事务的处理过程中查询同一记录两次的结果可能不一致（该记录被其他事务操作并提交了）； Time A B 0 insert into user(name,age,sex) values(‘张三’,20,1); 1 start transaction; 2 update user set age = age + 1 where name = ‘张三’; 3 start transaction; 4 select age from user where name = ‘张三’;(result: 20) 5 commit; 6 select age from user where name = ‘张三’;(result: 21) Time6：A 在事务 B 开启后提交，此时 B 已经可以读取到 A 事务操作的最新数据，即对 B 来说，两次读取同一记录结果不一致) 幻读：在一个事务的处理过程中相同查询执行两次，可能产生不一样的结果集，即产生幻行； Time A B 0 insert into user(name,age,sex) values(‘张三’,20,1); 1 start transaction; 2 insert into user(name,age,sex) values(‘李四’,30,1); 3 start transaction; 4 select count(1) from user; (result: 1) 5 commit; 6 select count(1) from user; (result: 2) Time6：A 在事务 B 开启后提交，此时 B 已经读取到 A 事务新增的李四这条数据，即对事务 B 来说，两次查询的结果集不一致，产生了幻行；innodb 通过 MVCC(多版本并发控制)解决幻读现象； 拓展： MVCC phantom rows","link":"/2021/03/28/Transaction-Isolation-Level/"},{"title":"Java Sandbox","text":"背景：在项目开发中，我们经常会遇到一些需要动态执行脚本的场景，比如：java执行一段页面编辑好的js脚本，如果存在恶意脚本的话，会引发一些安全问题。因此，一方面我们可以通过制定业务使用规则来限制脚本的内容； 而另一种则是通过沙箱来限制脚本的执行环境。 沙箱：沙箱通常是一种受控的执行环境，应用程序在其中运行，但受到限制以防止其访问敏感资源或执行恶意操作。 有以下几个方面： 资源隔离: 将应用程序限制在其分配的资源范围内，例如内存、CPU、文件系统访问等，防止应用程序对系统资源的滥用。 权限控制: 沙箱机制可以限制应用程序的权限，确保其只能访问必要的资源和功能，防止其执行潜在危险的操作。 环境隔离: 沙箱可以在一个隔离的环境中运行应用程序，使其与系统的其他部分隔离开来。这有助于防止应用程序对系统的其他部分产生影响，即使应用程序本身被感染或受到攻击也能够最大程度地减少潜在的损害。 常见的沙箱技术有：虚拟机JVM、Docker、浏览器沙箱等。 Java 沙箱：Java沙箱机制的主要包括以下几个方面： 字节码验证: 保字节码不包含任何违反Java语言规范的内容，以防止恶意代码通过修改字节码来执行恶意操作。 类加载器限制: Java应用程序中的类由类加载器加载。Java沙箱通过限制类加载器的行为来确保应用程序只能加载系统允许的类，防止恶意类的加载。 安全管理器: Java沙箱使用安全管理器（Security Manager）来控制应用程序对系统资源的访问。安全管理器定义了一组权限，指定了应用程序可以执行的操作类型和访问的资源范围。 操作系统访问限制: Java沙箱还通过限制应用程序对底层操作系统的直接访问来提高安全性。例如，Java应用程序不能直接访问底层文件系统或执行本地操作系统命令，必须通过Java API来进行操作。 Java 开启沙箱：以下通过一个简单例子来演示java沙箱： 1、编写一个读取文件的java程序，默认执行不开启沙箱，此时可以正常读取文件内容。 12String content = FileUtils.readFileToString(new File(&quot;/tmp/test.sh&quot;), StandardCharsets.UTF_8);System.out.println(content); 2、开启沙箱：java -Djava.security.manager Test, 读取文件会报错： 1Exception in thread &quot;main&quot; java.security.AccessControlException: access denied (&quot;java.io.FilePermission&quot; &quot;/tmp/test.sh&quot; &quot;read&quot;) 3、添加策略policy文件/tmp/custom.policy，授予对应文件路径的读权限： 123grant { permission java.io.FilePermission &quot;/tmp/test.sh&quot;, &quot;read&quot;;}; 这里的permission可以参考：Permissions in the Java Development Kit (JDK) 4、再次启动：java -Djava.security.manager -Djava.security.policy=/tmp/custom.policy Test，可以正常读取文件内容。 Nashorn - Java执行Js沙箱： https://github.com/javadelight/delight-nashorn-sandbox 参考： The Security Manager Permissions in the Java Development Kit (JDK) K：java中的安全模型(沙箱机制))","link":"/2024/03/21/Java-Sandbox/"}],"tags":[{"name":"IT","slug":"IT","link":"/tags/IT/"},{"name":"DolphinScheduler","slug":"DolphinScheduler","link":"/tags/DolphinScheduler/"},{"name":"book","slug":"book","link":"/tags/book/"},{"name":"linux","slug":"linux","link":"/tags/linux/"},{"name":"lock","slug":"lock","link":"/tags/lock/"},{"name":"management","slug":"management","link":"/tags/management/"},{"name":"trace","slug":"trace","link":"/tags/trace/"},{"name":"Database","slug":"Database","link":"/tags/Database/"},{"name":"sandbox","slug":"sandbox","link":"/tags/sandbox/"}],"categories":[{"name":"DolphinScheduler","slug":"DolphinScheduler","link":"/categories/DolphinScheduler/"},{"name":"Book","slug":"Book","link":"/categories/Book/"},{"name":"Linux","slug":"Linux","link":"/categories/Linux/"},{"name":"Java","slug":"Java","link":"/categories/Java/"},{"name":"Monitor","slug":"Monitor","link":"/categories/Monitor/"},{"name":"Database","slug":"Database","link":"/categories/Database/"}],"pages":[]}